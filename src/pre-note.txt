Slide 1: 
    Hi everyone! Thank you for showing up! 
    Today, I'd like to share a project that Daniel and I and a couple of other collaborators have been working on. 
    This project is about developing a model to estimate the effective reproduction number. 

Slide 2:
    Let's start with the definition of effective reproduction number, which is denoted as Rt. 
    Rt is the expected number of secondary infections caused by a primary infection in a population at time t.
    So it can be regarded as a rate. A rate of secondary infections over all primary infections at a specific time. 
    --
    So now let's write Rt as a rate like in this fraction, where the numerator is the number of secondary infections ... the number of primary infections.
    --
    Here we assume a constant proportion of observable infections over all infections in nature, denoted by c.
    Nt denotes the number of observable infections at t, so Nt/c is the total number of infections at t.
    And it's the same for the primary infections.
    --
    There are a few components in the function of primary infections. 
    In short, it is a weighted sum of previous infection counts over a certain period prior to time t. 
    where Phi_t is the certain period for time t, 
    and p_i is the probability that a primary infection at time t-i causes a secondary infection at time t. 
    As you may realize that this period between the primary and secondary infections is called generation time. We approximate it by serial interval function, since generation time is unobservable. 
    Here we assume serial interval is independent to the calendar time t, which implies that its distribution is the same for all t. 

Slide 3:
    Now, let's rearrange the terms in the function of Rt. And it gives us the renewal equation, where p_i*Rt is usually written as a single term to represent the infectiousness of a primary infection at time i to secondary infections at time t. 
    --
    We make a further assumption that the daily infections y_t at time t follows a Poisson distribution with mean of Nt.
    And we let w_t denote the primary infections. Then we get y_t follows Poisson of w_tRt. 
    We assume the serial interval follows a Gamma distribution. Then we can compute the probability p_i and further compute w_t.

Slide 4:
    To be more specific on how the probabilities are calculated, let's see a simple demonstration. This is a histogram of the Gamma samples and its corresponding theoretical density curve. The probabilities are the cumulative probabilities between different contiguous ranges, like the ranges of the bins in the histogram, since we observe discretized timepoints. 

Slide 5: 
    Then, after we compute each p_i for time t, we reweight the probabilities by their sums, so that the sum of p_i's is 1. Since the total probability of a secondary infection being infected is one. 
    Then we can compute w_t by approximating N_t-i by the observed case counts y_t-i. 

Slide 6:
    So then given y_t and w_t, we can compute Rt. An intuitive way is to find the MLE of Rt, since it's a parameter of Poisson distribution. And if we let theta represent the natural logarithm of Rt, the problem can be written as the sum of y_t\theta_t minus w_t exp(theta_t). 
    If we simply solve this problem, the estimated Rt's have a one-to-one correspondence with y_t's. But we don't want to do this, because, in this case, the estimated curves are going to be too wiggly.
    We want to further assume the smoothness structure of Rt. Specifically, they are piecewise polynomials.
    We regularize the similarity across neighboring Rt's. 
    Here, we consider the divided difference between neighboring theta's with different orders. A higher order means the similarity across more neighboring theta's. 
    We use the ell_1 penalty. The ell_1 penalty here is exactly the trend filtering penalty, where the divided difference operator is a banded matrix. 
    --
    There are a couple of advantages of using this penalty. The estimators are locally adaptive, which means the estimators can be more wiggly in some regions and more smooth in the others. 
    And it is computationally friendly.

Slide 7:
    This is a simple demonstration of the estimated curves by trend filtering. The lowest degree returns piecewise-constant curves, and a higher degree (k) returns a polynomial with a higher degree. 

Slide 8:
    Now, let's define the divided difference operator rigorously. It is a banded matrix with a shrinking number of rows for a higher order. 
    --
    For example, the lowest two orders are shown here. This lowest order has a band (-1,1) and the second order has the band (1,-2,1).
    --
    Generally, the band of the divided difference operator takes values from the Yanghui's or Pascal's triangle with alternating signs. For example, the band of D^3 is (-1,3,-3,1). 

Slide 9:
    Until now, we've discussed all the necessary components to construct the model. So let's define the model rigorously. It is a minimization problem with the objective to be the sum of two terms. 
    The first term is the Poisson loss and the second term is the trend filtering penalty. 
    The two terms are balanced by the hyperparameter lambda with a larger lambda regularizing more on the smoothness. 
    --
    As we've discussed, this problem can be viewed as trend filtering with Poisson loss. 
    It is a convex problem with a global optimum. 
    And we solve it by the proximal Newton method. 

Slide 10:
    The proximal Newton method, in short, involves approximation and decomposition. In general, it solves an approximate problem iteratively using the Newton's method and decompose the approximated problem into subproblems in each iterate. 
    -- 
    More specifically, for each iterate, it replaces the Poisson loss by its second-order Taylor expansion. Like the way we solve the generalized linear regression using iteratively reweighted least squares. 
    And then the problem can be written as this minimization problem, which is the weighted trend filtering that can be solved using Ramdas's specialized ADMM. 
    -- 
    It's followed a backtracking linesearch algorithm to adjust the step size. And then the two steps run iteratively until the convergence of the objective. 

Slide 11:
    There are some other computational considerations. 

Slide 12:
    Now, let's compare the empirical performance of our model to a widely used method, EpiEstim. 
    Let's design the experiments first. 
    Ultimately, we need to generate y_t from Poisson distribution with mean Nt. 
        Before this, we generate the N_t's following the renewal equation, where we compute p_i using Gamma with scale 2.5 and shape 2.5, generate R_t to be step function with boxcar kernel transformations, and assume the first infection N_1 to be 2. The infection period Phi_t is t-1, which implies we use all previous case counts. 
    Then we repeat the whole step for 30 times to generate 30 random samples. Each sample has 700 observations.
    --
    Then, we consider two alternative scenarios when an assumption is violated. 
    For the scenario where the smoothing assumption is violated, we use the step function directly to be the reproduction number. 
    For the scenario where the Poisson assumption is violated, we generate samples from negative binomial distribution with mean N_t and an overdispersion parameter r=8. 

Slide 13:
    To evaluate the performance, we use rooted mean squared error to measure the deviation of the estimated reproduction number from the true reproduction number. 
    We use the estimated Rt to compute the estimated infections N^hat following the renewal equation. And then measure the distance using the mean absolute error. 
    We compare the performance of our model to EpiEstim, which is a Bayesian framework using the Poisson distributional assumption and Gamma prior of Rt. We set its sliding window to be 7 days.

Slide 14: 
    These two figures shows the realization of the first scenario where all assumptions are satisfied. 
    The left figure shows a sample Rt and Nt, where the orange curves are our model (RtEstim), the blue curves are estimates of EpiEstim, and the gray lines are the true values, which are almost overlap with our estimates.
    The right figure shows the empirical performance. 
    We can see our model has a small RMSE and MAE compared to EpiEstim. 

Slide 15:
    The second scenario uses the step function to be Rt. It has similar results as the first case.

Slide 16:
    The third scenario has sample case counts generated following negative binomial distribution. And it draws similar conclusions as well.

Slide 17:
    The main findings from the empirical evaluations are that 
    our model outperforms EpiEstim in terms of the accuracy of Rt estimation,
     and our model is robust in the violation of smoothness and distributional assumptions.

Slide 18:
    This is an application on Covid-19 reproduction number estimation for British Columbia, Canada. We consider case counts between March 1st, 2020 and April 15, 2023.
    The up-left panel shows the case counts, and the following panels show the Piecewise-linear, quadratic and cubic Rt estimates with various lambda sequences. 
    We can tell that the infection expands when Rt is greater than 1, and the pandemic dies out when Rt is smaller than 1.

Slide 19:
    Now, let's wrap it up. We construct a convex optimization problem for effective reproduction number estimation. It can be regarded as trend filtering with Poisson loss on univariate data.
    The estimators are piecewise-polynomials and locally adaptive. 
    It is computationally efficient.
    And it empirically outperforms EpiEstim regarding the accuracy of Rt.
    It is robust in the violation of distributional and smoothness assumptions.

Slide 20:
    That's all. Thank you for listening! I'll happy to take any questions. 
